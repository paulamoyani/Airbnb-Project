{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "import matplotlib\n",
    "import sklearn\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.9)\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "# TO WORK WITH\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import set_printoptions\n",
    "\n",
    "# HIDE WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PREPROCESSING & MODEL SELECTION\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, RidgeCV, LassoCV, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import SCORERS\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# print(SCORERS.keys())\n",
    "\n",
    "# PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.lines as mlines\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "import plotly.express as px\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# STANDARD MODELS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ENSEMBLE\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# CLUSTERING\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# PICKLE\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2181.000000\n",
       "mean      170.812471\n",
       "std       192.218113\n",
       "min         0.000000\n",
       "25%        25.000000\n",
       "50%       100.000000\n",
       "75%       235.000000\n",
       "max      1024.000000\n",
       "Name: extra_price, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2181 entries, 0 to 2767\n",
      "Data columns (total 81 columns):\n",
      "transit_bool                                      2181 non-null bool\n",
      "nopets_bool                                       2181 non-null bool\n",
      "nosmok_bool                                       2181 non-null bool\n",
      "fewdays_response_time                             2181 non-null bool\n",
      "1day_response_time                                2181 non-null bool\n",
      "1hour_response_time                               2181 non-null bool\n",
      "fewhours_response_time                            2181 non-null bool\n",
      "host_is_superhost                                 2181 non-null bool\n",
      "host_identity_verified                            2181 non-null bool\n",
      "is_location_exact                                 2181 non-null bool\n",
      "accommodates                                      2181 non-null int64\n",
      "bathrooms                                         2181 non-null float64\n",
      "bedrooms                                          2181 non-null float64\n",
      "beds                                              2181 non-null float64\n",
      "Wheelchair_bool                                   2181 non-null bool\n",
      "TV_bool                                           2181 non-null bool\n",
      "Hair Dryer_bool                                   2181 non-null bool\n",
      "24-Hour_Check-in_bool                             2181 non-null bool\n",
      "Doorman_bool                                      2181 non-null bool\n",
      "Gym_bool                                          2181 non-null bool\n",
      "Kitchen_bool                                      2181 non-null bool\n",
      "Smoke_Detector_bool                               2181 non-null bool\n",
      "Clothes_Dryer_bool                                2181 non-null bool\n",
      "Kitchen_boolean                                   2181 non-null bool\n",
      "Elevator_in_building_bool                         2181 non-null bool\n",
      "Pets_live_in_flat_bool                            2181 non-null bool\n",
      "Free_Parking_bool                                 2181 non-null bool\n",
      "Heating_bool                                      2181 non-null bool\n",
      "Clothes_Washer_bool                               2181 non-null bool\n",
      "Wireless_Internet_bool                            2181 non-null bool\n",
      "AC_bool                                           2181 non-null bool\n",
      "Internet_bool                                     2181 non-null bool\n",
      "price_per_night                                   2181 non-null int64\n",
      "guests_included                                   2181 non-null int64\n",
      "instant_bookable                                  2181 non-null bool\n",
      "super_strict_canc                                 2181 non-null bool\n",
      "moderate_cancellation                             2181 non-null bool\n",
      "strict_cancellation                               2181 non-null bool\n",
      "flexible_cancellation                             2181 non-null bool\n",
      "require_guest_profile_picture                     2181 non-null bool\n",
      "require_guest_phone_verification                  2181 non-null bool\n",
      "neighbourhood_cleansed_Allston                    2181 non-null uint8\n",
      "neighbourhood_cleansed_Back Bay                   2181 non-null uint8\n",
      "neighbourhood_cleansed_Bay Village                2181 non-null uint8\n",
      "neighbourhood_cleansed_Beacon Hill                2181 non-null uint8\n",
      "neighbourhood_cleansed_Brighton                   2181 non-null uint8\n",
      "neighbourhood_cleansed_Charlestown                2181 non-null uint8\n",
      "neighbourhood_cleansed_Chinatown                  2181 non-null uint8\n",
      "neighbourhood_cleansed_Dorchester                 2181 non-null uint8\n",
      "neighbourhood_cleansed_Downtown                   2181 non-null uint8\n",
      "neighbourhood_cleansed_East Boston                2181 non-null uint8\n",
      "neighbourhood_cleansed_Fenway                     2181 non-null uint8\n",
      "neighbourhood_cleansed_Hyde Park                  2181 non-null uint8\n",
      "neighbourhood_cleansed_Jamaica Plain              2181 non-null uint8\n",
      "neighbourhood_cleansed_Leather District           2181 non-null uint8\n",
      "neighbourhood_cleansed_Longwood Medical Area      2181 non-null uint8\n",
      "neighbourhood_cleansed_Mattapan                   2181 non-null uint8\n",
      "neighbourhood_cleansed_Mission Hill               2181 non-null uint8\n",
      "neighbourhood_cleansed_North End                  2181 non-null uint8\n",
      "neighbourhood_cleansed_Roslindale                 2181 non-null uint8\n",
      "neighbourhood_cleansed_Roxbury                    2181 non-null uint8\n",
      "neighbourhood_cleansed_South Boston               2181 non-null uint8\n",
      "neighbourhood_cleansed_South Boston Waterfront    2181 non-null uint8\n",
      "neighbourhood_cleansed_South End                  2181 non-null uint8\n",
      "neighbourhood_cleansed_West End                   2181 non-null uint8\n",
      "neighbourhood_cleansed_West Roxbury               2181 non-null uint8\n",
      "property_type_Apartment                           2181 non-null uint8\n",
      "property_type_Bed & Breakfast                     2181 non-null uint8\n",
      "property_type_Boat                                2181 non-null uint8\n",
      "property_type_Condominium                         2181 non-null uint8\n",
      "property_type_Dorm                                2181 non-null uint8\n",
      "property_type_Entire Floor                        2181 non-null uint8\n",
      "property_type_Guesthouse                          2181 non-null uint8\n",
      "property_type_House                               2181 non-null uint8\n",
      "property_type_Loft                                2181 non-null uint8\n",
      "property_type_Other                               2181 non-null uint8\n",
      "property_type_Townhouse                           2181 non-null uint8\n",
      "property_type_Villa                               2181 non-null uint8\n",
      "room_type_Entire home/apt                         2181 non-null uint8\n",
      "room_type_Private room                            2181 non-null uint8\n",
      "room_type_Shared room                             2181 non-null uint8\n",
      "dtypes: bool(35), float64(3), int64(3), uint8(40)\n",
      "memory usage: 279.0 KB\n"
     ]
    }
   ],
   "source": [
    "    data = pd.read_csv(\"listings_8.csv\")\n",
    "    data=data.dropna()\n",
    "    \n",
    "    data=data[data[\"price_per_night\"]>=12]\n",
    "    data=data[data[\"number_of_reviews\"]>=1]\n",
    "    data=data[data[\"guests_included\"]>=1]\n",
    "    \n",
    "    \n",
    "\n",
    "    data['extra_price']=data['security_deposit']+data['cleaning_fee']+data['extra_people']\n",
    "    data['extra_price'].describe()\n",
    "    \n",
    "    \n",
    "    for test in data['extra_price']:\n",
    "       \n",
    "        if test<25:\n",
    "            data['extra_price']=25\n",
    "    \n",
    "    \n",
    "        if 25<test and test<100:\n",
    "            data['extra_price']=75\n",
    "    \n",
    "    \n",
    "        if 100<test and test<235:\n",
    "            data['extra_price']=125\n",
    "    \n",
    "    \n",
    "        if 235<test:\n",
    "            data['extra_price']=235\n",
    "            \n",
    "#             \"bedrooms\",\"accommodates\", \"bathrooms\",\"beds\"\n",
    "    \n",
    "#     scaler=MinMaxScaler(feature_range=(0,1))\n",
    "#     data[['extra_price']] = scaler.fit_transform(data[['extra_price']])\n",
    "#     data.info()\n",
    "    \n",
    "    for categorical_feature in ['neighbourhood_cleansed',\"property_type\",\"room_type\"]:\n",
    "        data = pd.concat([data,pd.get_dummies(data[categorical_feature], prefix=categorical_feature, prefix_sep='_',)], axis=1)\n",
    "        \n",
    "#     data.head()\n",
    "    \n",
    "    data= data.drop(['neighbourhood_cleansed', 'property_type', 'room_type','description','host_about_bool',\n",
    "                    'amenities',\"house_rules\",\"review_scores_cleanliness\",\"review_scores_rating\",'review_scores_accuracy',              \n",
    "                    'review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_value',\n",
    "                     'id',\"property_type\", \"host_response_rate\", 'reviews_per_month','number_of_reviews'\n",
    "                     ,'security_deposit','cleaning_fee','extra_people','extra_price','availability_365'\n",
    "#                      ,\"beds\",\"bathrooms\",,\"bedrooms\",\"accommodates\",\"guests_included\",\n",
    "                     ],axis=1)\n",
    "    \n",
    "    data.info()\n",
    "    \n",
    "    y = data[\"price_per_night\"] # Target variable (price_per_night)\n",
    "    \n",
    "    X = data.drop([\"price_per_night\"],axis=1) \n",
    "#     print(\"this is X\")\n",
    "#     X.info()\n",
    "#     pd.DataFrame(data)\n",
    "#     scaler=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>available</th>\n",
       "      <th>price1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3353</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3353</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3353</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3353</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3353</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        date  available  price1\n",
       "0        3353  2016-12-31       True      32\n",
       "1        3353  2017-01-01       True      32\n",
       "2        3353  2017-01-02       True      32\n",
       "3        3353  2017-01-03       True      32\n",
       "4        3353  2017-01-04       True      32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 643037 entries, 0 to 643036\n",
      "Data columns (total 4 columns):\n",
      "listing_id    643037 non-null int64\n",
      "date          643037 non-null object\n",
      "available     643037 non-null bool\n",
      "price1        643037 non-null int64\n",
      "dtypes: bool(1), int64(2), object(1)\n",
      "memory usage: 15.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>6.430370e+05</td>\n",
       "      <td>643037.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>7.699288e+06</td>\n",
       "      <td>191.691385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>4.766178e+06</td>\n",
       "      <td>140.786595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>3.353000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.616081e+06</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>7.789055e+06</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.228796e+07</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.493346e+07</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         listing_id         price1\n",
       "count  6.430370e+05  643037.000000\n",
       "mean   7.699288e+06     191.691385\n",
       "std    4.766178e+06     140.786595\n",
       "min    3.353000e+03       1.000000\n",
       "25%    3.616081e+06      85.000000\n",
       "50%    7.789055e+06     150.000000\n",
       "75%    1.228796e+07     250.000000\n",
       "max    1.493346e+07     999.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 643037 entries, 0 to 643036\n",
      "Data columns (total 3 columns):\n",
      "listing_id    643037 non-null int64\n",
      "date          643037 non-null object\n",
      "price1        643037 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 14.7+ MB\n"
     ]
    }
   ],
   "source": [
    "calendar =pd.read_csv(\"calendar_cleaned.csv\")\n",
    "calendar.head()\n",
    "calendar.info()\n",
    "calendar.describe()\n",
    "calendar=calendar.drop(\"available\",axis=1)\n",
    "calendar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# kfold=KFold(n_splits=15, random_state=7)\n",
    "\n",
    "# model=DecisionTreeRegressor()\n",
    "# scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "# results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "# print(f'Decision Trees Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # KNN Regression \n",
    "\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "# model=KNeighborsRegressor()\n",
    "# scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "# results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "# print(f'KNN Regression - MSE {results.mean():.3f} std {results.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Linear Regression with scikit-learn\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression       # if large--> r square\n",
    "#                                                         # if part of data--> does not work well!! \n",
    "# kfold=KFold(n_splits=10, random_state=7)                # sklearn better higher w fi chi bel ma2loub!! \n",
    "#                                     #same results BUT DIFFERENT WAY TO USE IT!!\n",
    "# model=LinearRegression()\n",
    "# scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "# results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "# print(f'Linear Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "\n",
    "# # Now lets use it in the same way than the statsmodel\n",
    "\n",
    "# model_x=LinearRegression()\n",
    "# model_x.fit(X,y)\n",
    "# print(f'Intercept {model_x.intercept_:.4f}')\n",
    "# print(\"Coefficients \",model_x.coef_)\n",
    "\n",
    "# y_pred_x=model_x.predict(X)\n",
    "\n",
    "# print(f'MAE - Mean Absolute Error {metrics.mean_absolute_error(y, y_pred_x):.3f}')\n",
    "# print(f'MSE - Mean Square Error  {metrics.mean_squared_error(y, y_pred_x):.3f}')\n",
    "# print(f'R2    {metrics.r2_score(y, y_pred_x):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:22:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.0.0/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=20, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=70, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:linear', random_state=0, reg_alpha=20, reg_lambda=1,\n",
       "             scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 62.013981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                max_depth = 7, alpha = 20, n_estimators = 70)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3424.025091074439\n",
    "# 58.51516975173565\n",
    "# -1.2280514018653326e+25\n",
    "\n",
    "\n",
    "# host_is_superhost\n",
    "# host_identity_verified \n",
    "# accommodates                        \n",
    "# bathrooms                           \n",
    "# bedrooms                            \n",
    "# beds                                \n",
    "# Wheelchair_bool                     \n",
    "# TV_bool                             \n",
    "# Hair Dryer_bool                     \n",
    "# 24-Hour_Check-in_bool               \n",
    "# Doorman_bool                        \n",
    "# Gym_bool                            \n",
    "# Kitchen_bool                        \n",
    "# Smoke_Detector_bool                 \n",
    "# Clothes_Dryer_bool                  \n",
    "# Kitchen_boolean     \n",
    "# Elevator_in_building_bool \n",
    "# Heating_bool\n",
    "\n",
    "# AC_bool                             \n",
    "# Internet_bool \n",
    "\n",
    "# cleaning_fee                        \n",
    "# guests_included \n",
    "\n",
    "# instant_bookable                    \n",
    "# super_strict_canc\n",
    "\n",
    "# require_guest_profile_picture  \n",
    "# require_guest_phone_verification \n",
    "\n",
    "# Allston                             \n",
    "# Back Bay                            \n",
    "# Bay Village                     \n",
    "# Beacon Hill                         \n",
    "# Brighton                            \n",
    "# Charlestown                         \n",
    "# Chinatown                           \n",
    "# Dorchester                          \n",
    "# Downtown                            \n",
    "# East Boston                         \n",
    "# Fenway                              \n",
    "# Hyde Park                           \n",
    "# Jamaica Plain                       \n",
    "# Leather District                    \n",
    "# Longwood Medical Area               \n",
    "# Mattapan                            \n",
    "# Mission Hill                        \n",
    "# North End                           \n",
    "# Roslindale                          \n",
    "# Roxbury                     \n",
    "# South Boston                        \n",
    "# South Boston Waterfront             \n",
    "# South End                           \n",
    "# West End                            \n",
    "# West Roxbury                       \n",
    "# Entire home/apt                     \n",
    "# Private room                        \n",
    "# Shared room   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#     data[['security_deposit']] = scaler.fit_transform(data[['security_deposit']])\n",
    "#     data[['cleaning_fee']] = scaler.fit_transform(data[['cleaning_fee']])\n",
    "#     data[['host_response_rate']] = scaler.fit_transform(data[['host_response_rate']])\n",
    "#     data[['price_per_night']] = scaler.fit_transform(data[['price_per_night']])\n",
    "    \n",
    "#     data[['accommodates']] = scaler.fit_transform(data[['accommodates']])\n",
    "#     data[['bathrooms']] = scaler.fit_transform(data[['bathrooms']])\n",
    "#     data[['bedrooms']] = scaler.fit_transform(data[['bedrooms']])\n",
    "#     data[['beds']] = scaler.fit_transform(data[['beds']])\n",
    "#     data[['guests_included']] = scaler.fit_transform(data[['guests_included']])\n",
    "#     data[['extra_people']] = scaler.fit_transform(data[['extra_people']])\n",
    "#     data[['availability_365']] = scaler.fit_transform(data[['availability_365']])\n",
    "#     data[['number_of_reviews']] = scaler.fit_transform(data[['number_of_reviews']])\n",
    "\n",
    "    \n",
    "#     data.info()\n",
    "#     data[\"host_response_rate\"]\n",
    "#     data.describe()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     calendar = pd.read_csv(\"calendar_cleaned.csv\")\n",
    "#     calendar.describe()\n",
    "#     calendar.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     data=data[[\"host_is_superhost\", \"host_identity_verified\", \"accommodates\", \"bathrooms\", \"bedrooms\",\n",
    "#          \"beds\", \"Wheelchair_bool\", \"TV_bool\", \"Hair Dryer_bool\", \"24-Hour_Check-in_bool\", \"Doorman_bool\",\n",
    "#          \"Gym_bool\", \"Kitchen_bool\", \"Smoke_Detector_bool\", \"Clothes_Dryer_bool\", \"Kitchen_boolean\",\n",
    "#          \"Elevator_in_building_bool\", \"Heating_bool\", \"AC_bool\", \"Internet_bool\", \"cleaning_fee\",\n",
    "#          \"guests_included\", \"instant_bookable\", \"super_strict_canc\", \"require_guest_profile_picture\",\n",
    "#          \"require_guest_phone_verification\", \"Allston\", \"Back Bay\", \"Bay Village\", \"Beacon Hill\", \"Brighton\",\n",
    "#          \"Charlestown\", \"Chinatown\", \"Dorchester\", \"Downtown\", \"East Boston\", \"Fenway\", \"Hyde Park\", \"Jamaica Plain\",\n",
    "#          \"Leather District\", \"Longwood Medical Area\", \"Mattapan\", \"Mission Hill\", \"North End\", \"Roslindale\", \"Roxbury\",\n",
    "#          \"South Boston\", \"South Boston Waterfront\", \"South End\", \"West End\", \"West Roxbury\", \"Entire home/apt\", \"Private room\",\n",
    "#          \"Shared room\",\"price_per_night\",\"cleaning_fee\"]]\n",
    "    \n",
    "#     for col in data.columns: \n",
    "#         print(col)\n",
    "#         print(col.types)\n",
    "       \n",
    "    \n",
    "    \n",
    "#     data.info()\n",
    "\n",
    "#     print(\"HI INFO\")\n",
    "#     data.describe()\n",
    "#     data.info()\n",
    "    \n",
    "#     data.describe()\n",
    "\n",
    "    \n",
    "    \n",
    "#     kfold=KFold(n_splits=10, random_state=7)\n",
    "#     model=LinearRegression()\n",
    "#     scoring = \"neg_mean_squared_error\"\n",
    "    \n",
    "# #     y_pred = clf.predict(data.drop('price_per_night', axis='columns'))\n",
    "    \n",
    "#     results=cross_val_score(model, X_wnei, y, cv=kfold, scoring=scoring)\n",
    "    \n",
    "#     clf = model.fit(X_wnei, y)\n",
    "    \n",
    "#     MSEs=[]\n",
    "#     MSEs.append((\"Linear Regression\", results.mean(), clf.coef_))\n",
    "#     print(MSEs)\n",
    "    \n",
    "    \n",
    "#     from sklearn.model_selection import KFold # import KFold\n",
    "    \n",
    "    \n",
    "#     kf = KFold(n_splits=2) # Define the split - into 2 folds \n",
    "#     kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "#     print(kf) \n",
    "#     KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#     print(“TRAIN:”, train_index, “TEST:”, test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     ('TRAIN:', array([2, 3]), 'TEST:', array([0, 1]))\n",
    "#     ('TRAIN:', array([0, 1]), 'TEST:', array([2, 3]))\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "#THIS IS THE BEST ONE!\n",
    "\n",
    "#     from sklearn.linear_model import LinearRegression\n",
    "#     from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "#     data_train, data_test, price_train, price_test = train_test_split(X, y,test_size=0.25,random_state=7)\n",
    "    \n",
    "#     model=LinearRegression()\n",
    "    \n",
    "#     model.fit(data_train,price_train)\n",
    "    \n",
    "#     predicted_price=model.predict(data_train)\n",
    "    \n",
    "#     mean_squared_error(price_train, predicted_price)\n",
    "    \n",
    "#     np.sqrt(mean_squared_error(price_train, predicted_price))  \n",
    "    \n",
    "    \n",
    "#     from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "#     ols2 = LinearRegression()\n",
    "#     ols_cv_mse = cross_val_score(ols2, data_train, price_train, scoring='neg_mean_squared_error', cv=4)\n",
    "#     ols_cv_mse.mean()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "#  evaluated with train & test - remember we have a high variance !  \n",
    "# it does everything and almost 1% better that's why people love it\n",
    "# # we need more test data!!!\n",
    "#     seed=7\n",
    "#     test_size=0.22\n",
    "\n",
    "# # split into train and test\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "# #############################################################\n",
    "\n",
    "# # XGBoost \n",
    "# #   evaluated with KFold\n",
    "# #   in this case we use 3 splits because the amount of data is not large\n",
    "\n",
    "#     kfold=KFold(n_splits=3, random_state=seed)\n",
    "    \n",
    "#     learner=DecisionTreeClassifier(class_weight=\"balanced\", random_state=seed)\n",
    "#     learner=xgb.XGBRegressor()\n",
    "\n",
    "#     xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 1, learning_rate = 0.01,\n",
    "#                          max_depth = 6, alpha = 4, n_estimators = 1000)\n",
    "\n",
    "# # learning_rate: 0.01\n",
    "# # n_estimators: 100 if the size of your data is high, 1000 is if it is medium-low\n",
    "# # max_depth: 3\n",
    "# # subsample: 0.8\n",
    "# # colsample_bytree: 1\n",
    "# # gamma: 1\n",
    "\n",
    "#     xg_reg.fit(X_train,y_train)\n",
    "\n",
    "#     preds = xg_reg.predict(X_test)\n",
    "\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "#     print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "\n",
    "#     eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "#     eval_metric = [\"auc\",\"error\"]\n",
    "\n",
    "    \n",
    "#     model.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)],eval_metric=[\"auc\",\"error\"], verbose=True)\n",
    "\n",
    "\n",
    "#     results=cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "#     print(f'XGBoost with kfold - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     seed=7\n",
    "#     kfold=KFold(n_splits=10, random_state=seed) #KFold\n",
    "\n",
    "\n",
    "\n",
    "#     num_trees=100\n",
    "#     num_features=4\n",
    "\n",
    "\n",
    "\n",
    "#     X_train,X_test, y_train, y_test=train_test_split(X,y,test_size=0.2, random_state=seed) #Seperating into tranin and test\n",
    "\n",
    "\n",
    "\n",
    "#     model=RandomForestClassifier(n_estimators=num_trees, max_features=num_features, random_state=seed) #model\n",
    "    \n",
    "#     results=cross_val_score(model, X, y, cv=kfold) #CV\n",
    "\n",
    "\n",
    "\n",
    "#     # Accuracy Before Pickling the model\n",
    "#     print(f'Random Forest - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "\n",
    "\n",
    "#     model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "#     # Now we save it into a file\n",
    "#     filename=\"PaulaMoya_RFC_model.sav\"\n",
    "#     dump(model, open(filename, \"wb\"))\n",
    "#     # .... some time later .... \n",
    "#     #load the model from disk\n",
    "#     loaded_model=load(open(filename, \"rb\"))\n",
    "#     result=loaded_model.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "#     # Accuracy After Pickling and loading the model\n",
    "#     print(f'Loaded model - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#     from sklearn.linear_model import LinearRegression       # if large--> r square\n",
    "#                                                             # if part of data--> does not work well!! \n",
    "#     kfold=KFold(n_splits=2, random_state=7)                # sklearn better higher w fi chi bel ma2loub!! \n",
    "#                                         #same results BUT DIFFERENT WAY TO USE IT!!\n",
    "#     model=LinearRegression()\n",
    "#     scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "#     results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "#     print(f'Linear Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "#     # res_w1[\"Res\"]=results\n",
    "#     # res_w1[\"Type\"]=\"Lin\"\n",
    "\n",
    "#     # resall=pd.concat([resall,res_w1], ignore_index=True)\n",
    "\n",
    "#     # Now lets use it in the same way than the statsmodel\n",
    "    \n",
    "    \n",
    "    \n",
    "#     len(data[\"host_response_rate\"])\n",
    "\n",
    "#     model_x=LinearRegression()\n",
    "#     model_x.fit(X,y)\n",
    "#     print(f'Intercept {model_x.intercept_:.4f}')\n",
    "#     print(\"Coefficients \",model_x.coef_)\n",
    "\n",
    "#     y_pred_x=model_x.predict(X)\n",
    "\n",
    "#     print(f'MAE - Mean Absolute Error {metrics.mean_absolute_error(y, y_pred_x):.3f}')\n",
    "#     print(f'MSE - Mean Square Error  {metrics.mean_squared_error(y, y_pred_x):.3f}')\n",
    "#     print(f'R2    {metrics.r2_score(y, y_pred_x):.3f}')    \n",
    "    \n",
    "    \n",
    "#     from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "#     clf = LinearRegression()\n",
    "#     y = data['price_per_night']\n",
    "#     clf.fit(data.drop('price_per_night', axis='columns'), y)\n",
    "\n",
    "#     y_pred = clf.predict(data.drop('price_per_night', axis='columns'))\n",
    "    \n",
    "#     import sklearn.metrics\n",
    "#     mse = sklearn.metrics.mean_squared_error(y, y_pred)\n",
    "#     print(\"mse:\")\n",
    "#     mse\n",
    "    \n",
    "    \n",
    "#     root_mse = mse**(1/2)\n",
    "#     print(\"root_mse:\")\n",
    "#     root_mse    #by how much we're missing out\n",
    "    \n",
    "#     print(\"r_squared:\")\n",
    "#     r_squared = sklearn.metrics.r2_score(y, y_pred)\n",
    "#     r_squared          #how much of the variance are we predicting\n",
    "    \n",
    "    # WE STILL HAVE ID TO LINK IT TO THE CALENDAR TABLE!\n",
    "\n",
    "#     y = data[\"price_per_night\"] # Target variable (price_per_night)\n",
    "#     X_wnei = data.drop([\"price_per_night\"],axis=1)\n",
    "    \n",
    "#     # Creating new DF without neighborhood names\n",
    "#     X_wnei.to_csv(\"X_wnei.csv\", index=False)\n",
    "#     data.to_csv(\"data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
