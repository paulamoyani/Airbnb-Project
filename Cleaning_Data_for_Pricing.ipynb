{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "import matplotlib\n",
    "import sklearn\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.9)\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "# TO WORK WITH\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import set_printoptions\n",
    "\n",
    "# HIDE WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PREPROCESSING & MODEL SELECTION\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, RidgeCV, LassoCV, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import SCORERS\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# print(SCORERS.keys())\n",
    "\n",
    "# PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.lines as mlines\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "import plotly.express as px\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# STANDARD MODELS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ENSEMBLE\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# CLUSTERING\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# PICKLE\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2181.000000\n",
       "mean      170.812471\n",
       "std       192.218113\n",
       "min         0.000000\n",
       "25%        25.000000\n",
       "50%       100.000000\n",
       "75%       235.000000\n",
       "max      1024.000000\n",
       "Name: extra_price, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2181 entries, 0 to 2767\n",
      "Columns: 130 entries, transit_bool to extra_price_75\n",
      "dtypes: bool(35), int64(1), uint8(94)\n",
      "memory usage: 308.8 KB\n",
      "HI INFO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_per_night</th>\n",
       "      <th>neighbourhood_cleansed_Allston</th>\n",
       "      <th>neighbourhood_cleansed_Back Bay</th>\n",
       "      <th>neighbourhood_cleansed_Bay Village</th>\n",
       "      <th>neighbourhood_cleansed_Beacon Hill</th>\n",
       "      <th>neighbourhood_cleansed_Brighton</th>\n",
       "      <th>neighbourhood_cleansed_Charlestown</th>\n",
       "      <th>neighbourhood_cleansed_Chinatown</th>\n",
       "      <th>neighbourhood_cleansed_Dorchester</th>\n",
       "      <th>neighbourhood_cleansed_Downtown</th>\n",
       "      <th>...</th>\n",
       "      <th>guests_included_4</th>\n",
       "      <th>guests_included_5</th>\n",
       "      <th>guests_included_6</th>\n",
       "      <th>guests_included_7</th>\n",
       "      <th>guests_included_8</th>\n",
       "      <th>guests_included_9</th>\n",
       "      <th>guests_included_10</th>\n",
       "      <th>guests_included_12</th>\n",
       "      <th>guests_included_14</th>\n",
       "      <th>extra_price_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.000000</td>\n",
       "      <td>2181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>171.959652</td>\n",
       "      <td>0.049060</td>\n",
       "      <td>0.090326</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.056855</td>\n",
       "      <td>0.047226</td>\n",
       "      <td>0.027510</td>\n",
       "      <td>0.016506</td>\n",
       "      <td>0.088492</td>\n",
       "      <td>0.047685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056855</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>111.414777</td>\n",
       "      <td>0.216043</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>0.073989</td>\n",
       "      <td>0.231618</td>\n",
       "      <td>0.212171</td>\n",
       "      <td>0.163602</td>\n",
       "      <td>0.127441</td>\n",
       "      <td>0.284074</td>\n",
       "      <td>0.213147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231618</td>\n",
       "      <td>0.097674</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.042796</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>849.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       price_per_night  neighbourhood_cleansed_Allston  \\\n",
       "count      2181.000000                     2181.000000   \n",
       "mean        171.959652                        0.049060   \n",
       "std         111.414777                        0.216043   \n",
       "min          20.000000                        0.000000   \n",
       "25%          85.000000                        0.000000   \n",
       "50%         150.000000                        0.000000   \n",
       "75%         225.000000                        0.000000   \n",
       "max         849.000000                        1.000000   \n",
       "\n",
       "       neighbourhood_cleansed_Back Bay  neighbourhood_cleansed_Bay Village  \\\n",
       "count                      2181.000000                         2181.000000   \n",
       "mean                          0.090326                            0.005502   \n",
       "std                           0.286713                            0.073989   \n",
       "min                           0.000000                            0.000000   \n",
       "25%                           0.000000                            0.000000   \n",
       "50%                           0.000000                            0.000000   \n",
       "75%                           0.000000                            0.000000   \n",
       "max                           1.000000                            1.000000   \n",
       "\n",
       "       neighbourhood_cleansed_Beacon Hill  neighbourhood_cleansed_Brighton  \\\n",
       "count                         2181.000000                      2181.000000   \n",
       "mean                             0.056855                         0.047226   \n",
       "std                              0.231618                         0.212171   \n",
       "min                              0.000000                         0.000000   \n",
       "25%                              0.000000                         0.000000   \n",
       "50%                              0.000000                         0.000000   \n",
       "75%                              0.000000                         0.000000   \n",
       "max                              1.000000                         1.000000   \n",
       "\n",
       "       neighbourhood_cleansed_Charlestown  neighbourhood_cleansed_Chinatown  \\\n",
       "count                         2181.000000                       2181.000000   \n",
       "mean                             0.027510                          0.016506   \n",
       "std                              0.163602                          0.127441   \n",
       "min                              0.000000                          0.000000   \n",
       "25%                              0.000000                          0.000000   \n",
       "50%                              0.000000                          0.000000   \n",
       "75%                              0.000000                          0.000000   \n",
       "max                              1.000000                          1.000000   \n",
       "\n",
       "       neighbourhood_cleansed_Dorchester  neighbourhood_cleansed_Downtown  \\\n",
       "count                        2181.000000                      2181.000000   \n",
       "mean                            0.088492                         0.047685   \n",
       "std                             0.284074                         0.213147   \n",
       "min                             0.000000                         0.000000   \n",
       "25%                             0.000000                         0.000000   \n",
       "50%                             0.000000                         0.000000   \n",
       "75%                             0.000000                         0.000000   \n",
       "max                             1.000000                         1.000000   \n",
       "\n",
       "       ...  guests_included_4  guests_included_5  guests_included_6  \\\n",
       "count  ...        2181.000000        2181.000000        2181.000000   \n",
       "mean   ...           0.056855           0.009629           0.013755   \n",
       "std    ...           0.231618           0.097674           0.116500   \n",
       "min    ...           0.000000           0.000000           0.000000   \n",
       "25%    ...           0.000000           0.000000           0.000000   \n",
       "50%    ...           0.000000           0.000000           0.000000   \n",
       "75%    ...           0.000000           0.000000           0.000000   \n",
       "max    ...           1.000000           1.000000           1.000000   \n",
       "\n",
       "       guests_included_7  guests_included_8  guests_included_9  \\\n",
       "count        2181.000000        2181.000000        2181.000000   \n",
       "mean            0.000459           0.001834           0.000459   \n",
       "std             0.021413           0.042796           0.021413   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%             0.000000           0.000000           0.000000   \n",
       "75%             0.000000           0.000000           0.000000   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       guests_included_10  guests_included_12  guests_included_14  \\\n",
       "count         2181.000000         2181.000000         2181.000000   \n",
       "mean             0.000459            0.000459            0.000459   \n",
       "std              0.021413            0.021413            0.021413   \n",
       "min              0.000000            0.000000            0.000000   \n",
       "25%              0.000000            0.000000            0.000000   \n",
       "50%              0.000000            0.000000            0.000000   \n",
       "75%              0.000000            0.000000            0.000000   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       extra_price_75  \n",
       "count          2181.0  \n",
       "mean              1.0  \n",
       "std               0.0  \n",
       "min               1.0  \n",
       "25%               1.0  \n",
       "50%               1.0  \n",
       "75%               1.0  \n",
       "max               1.0  \n",
       "\n",
       "[8 rows x 95 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:24:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.0.0/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=4, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.01, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:linear', random_state=0, reg_alpha=4, reg_lambda=1,\n",
       "             scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 55.191470\n"
     ]
    }
   ],
   "source": [
    "    data = pd.read_csv(\"listings_8.csv\")\n",
    "    data=data.dropna()\n",
    "    \n",
    "    data=data[data[\"number_of_reviews\"]>=1]\n",
    "    data=data[data[\"guests_included\"]>=1]\n",
    "    \n",
    "    \n",
    "\n",
    "    data['extra_price']=data['security_deposit']+data['cleaning_fee']+data['extra_people']\n",
    "    data['extra_price'].describe()\n",
    "    \n",
    "    \n",
    "    for test in data['extra_price']:\n",
    "       \n",
    "        if test<25:\n",
    "            data['extra_price']=25\n",
    "    \n",
    "    \n",
    "        if 25<test and test<100:\n",
    "            data['extra_price']=75\n",
    "    \n",
    "    \n",
    "        if 100<test and test<235:\n",
    "            data['extra_price']=125\n",
    "    \n",
    "    \n",
    "        if 235<test:\n",
    "            data['extra_price']=235\n",
    "            \n",
    "            \n",
    "    \n",
    "    for categorical_feature in ['neighbourhood_cleansed',\"bedrooms\",\"property_type\",\n",
    "                                \"room_type\",\"accommodates\", \"bathrooms\",\"beds\",\"guests_included\",\n",
    "                               'extra_price']:\n",
    "        data = pd.concat([data,pd.get_dummies(data[categorical_feature], prefix=categorical_feature, prefix_sep='_',)], axis=1)\n",
    "        \n",
    "#     data.head()\n",
    "    \n",
    "    data= data.drop(['neighbourhood_cleansed', 'property_type', 'room_type','description','host_about_bool',\n",
    "                    'amenities',\"house_rules\",\"review_scores_cleanliness\",\"review_scores_rating\",'review_scores_accuracy',              \n",
    "                    'review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_value',\n",
    "                     'id',\"bedrooms\",\"property_type\",\"accommodates\", \"bathrooms\",\"beds\",\"guests_included\",\n",
    "                     \"host_response_rate\", 'availability_365', 'reviews_per_month','number_of_reviews',\n",
    "                     'security_deposit','cleaning_fee','extra_people','extra_price'\n",
    "                     ],axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    \n",
    "#     data[['security_deposit']] = scaler.fit_transform(data[['security_deposit']])\n",
    "#     data[['cleaning_fee']] = scaler.fit_transform(data[['cleaning_fee']])\n",
    "#     data[['host_response_rate']] = scaler.fit_transform(data[['host_response_rate']])\n",
    "#     data[['price_per_night']] = scaler.fit_transform(data[['price_per_night']])\n",
    "    \n",
    "#     data[['accommodates']] = scaler.fit_transform(data[['accommodates']])\n",
    "#     data[['bathrooms']] = scaler.fit_transform(data[['bathrooms']])\n",
    "#     data[['bedrooms']] = scaler.fit_transform(data[['bedrooms']])\n",
    "#     data[['beds']] = scaler.fit_transform(data[['beds']])\n",
    "#     data[['guests_included']] = scaler.fit_transform(data[['guests_included']])\n",
    "#     data[['extra_people']] = scaler.fit_transform(data[['extra_people']])\n",
    "#     data[['availability_365']] = scaler.fit_transform(data[['availability_365']])\n",
    "#     data[['number_of_reviews']] = scaler.fit_transform(data[['number_of_reviews']])\n",
    "\n",
    "    \n",
    "#     data.info()\n",
    "#     data[\"host_response_rate\"]\n",
    "#     data.describe()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     calendar = pd.read_csv(\"calendar_cleaned.csv\")\n",
    "#     calendar.describe()\n",
    "#     calendar.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     data=data[[\"host_is_superhost\", \"host_identity_verified\", \"accommodates\", \"bathrooms\", \"bedrooms\",\n",
    "#          \"beds\", \"Wheelchair_bool\", \"TV_bool\", \"Hair Dryer_bool\", \"24-Hour_Check-in_bool\", \"Doorman_bool\",\n",
    "#          \"Gym_bool\", \"Kitchen_bool\", \"Smoke_Detector_bool\", \"Clothes_Dryer_bool\", \"Kitchen_boolean\",\n",
    "#          \"Elevator_in_building_bool\", \"Heating_bool\", \"AC_bool\", \"Internet_bool\", \"cleaning_fee\",\n",
    "#          \"guests_included\", \"instant_bookable\", \"super_strict_canc\", \"require_guest_profile_picture\",\n",
    "#          \"require_guest_phone_verification\", \"Allston\", \"Back Bay\", \"Bay Village\", \"Beacon Hill\", \"Brighton\",\n",
    "#          \"Charlestown\", \"Chinatown\", \"Dorchester\", \"Downtown\", \"East Boston\", \"Fenway\", \"Hyde Park\", \"Jamaica Plain\",\n",
    "#          \"Leather District\", \"Longwood Medical Area\", \"Mattapan\", \"Mission Hill\", \"North End\", \"Roslindale\", \"Roxbury\",\n",
    "#          \"South Boston\", \"South Boston Waterfront\", \"South End\", \"West End\", \"West Roxbury\", \"Entire home/apt\", \"Private room\",\n",
    "#          \"Shared room\",\"price_per_night\",\"cleaning_fee\"]]\n",
    "    \n",
    "    data.info()\n",
    "\n",
    "    print(\"HI INFO\")\n",
    "    data.describe()\n",
    "    \n",
    "#     data.describe()\n",
    "    y = data[\"price_per_night\"] # Target variable (price_per_night)\n",
    "    \n",
    "    X = data.drop([\"price_per_night\"],axis=1)    \n",
    "    \n",
    "    \n",
    "#     kfold=KFold(n_splits=10, random_state=7)\n",
    "#     model=LinearRegression()\n",
    "#     scoring = \"neg_mean_squared_error\"\n",
    "    \n",
    "# #     y_pred = clf.predict(data.drop('price_per_night', axis='columns'))\n",
    "    \n",
    "#     results=cross_val_score(model, X_wnei, y, cv=kfold, scoring=scoring)\n",
    "    \n",
    "#     clf = model.fit(X_wnei, y)\n",
    "    \n",
    "#     MSEs=[]\n",
    "#     MSEs.append((\"Linear Regression\", results.mean(), clf.coef_))\n",
    "#     print(MSEs)\n",
    "    \n",
    "    \n",
    "#     from sklearn.model_selection import KFold # import KFold\n",
    "    \n",
    "    \n",
    "#     kf = KFold(n_splits=2) # Define the split - into 2 folds \n",
    "#     kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "#     print(kf) \n",
    "#     KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#     print(“TRAIN:”, train_index, “TEST:”, test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     ('TRAIN:', array([2, 3]), 'TEST:', array([0, 1]))\n",
    "#     ('TRAIN:', array([0, 1]), 'TEST:', array([2, 3]))\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "#THIS IS THE BEST ONE!\n",
    "\n",
    "#     from sklearn.linear_model import LinearRegression\n",
    "#     from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "#     data_train, data_test, price_train, price_test = train_test_split(X, y,test_size=0.25,random_state=7)\n",
    "    \n",
    "#     model=LinearRegression()\n",
    "    \n",
    "#     model.fit(data_train,price_train)\n",
    "    \n",
    "#     predicted_price=model.predict(data_train)\n",
    "    \n",
    "#     mean_squared_error(price_train, predicted_price)\n",
    "    \n",
    "#     np.sqrt(mean_squared_error(price_train, predicted_price))  \n",
    "    \n",
    "    \n",
    "#     from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "#     ols2 = LinearRegression()\n",
    "#     ols_cv_mse = cross_val_score(ols2, data_train, price_train, scoring='neg_mean_squared_error', cv=4)\n",
    "#     ols_cv_mse.mean()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# XGBoost\n",
    "#  evaluated with train & test - remember we have a high variance !  \n",
    "# it does everything and almost 1% better that's why people love it\n",
    "# we need more test data!!!\n",
    "seed=7\n",
    "test_size=0.22\n",
    "\n",
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "#############################################################\n",
    "\n",
    "# XGBoost \n",
    "#   evaluated with KFold\n",
    "#   in this case we use 3 splits because the amount of data is not large\n",
    "\n",
    "# kfold=KFold(n_splits=3, random_state=seed)\n",
    "\n",
    "#learner=DecisionTreeClassifier(class_weight=\"balanced\", random_state=seed)\n",
    "# learner=xgb.XGBRegressor()\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 1, learning_rate = 0.01,\n",
    "                          max_depth = 6, alpha = 4, n_estimators = 1000)\n",
    "\n",
    "# learning_rate: 0.01\n",
    "# n_estimators: 100 if the size of your data is high, 1000 is if it is medium-low\n",
    "# max_depth: 3\n",
    "# subsample: 0.8\n",
    "# colsample_bytree: 1\n",
    "# gamma: 1\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "\n",
    "# eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "# eval_metric = [\"auc\",\"error\"]\n",
    "\n",
    "# model.fit(X_train, y_train,  eval_set=[(X_train, y_train),eval_metric=[\"auc\",\"error\"], (X_test, y_test)], verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# results=cross_val_score(model, X, y, cv=kfold)\n",
    "\n",
    "# print(f'XGBoost with kfold - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "#######################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     seed=7\n",
    "#     kfold=KFold(n_splits=10, random_state=seed) #KFold\n",
    "\n",
    "\n",
    "\n",
    "#     num_trees=100\n",
    "#     num_features=4\n",
    "\n",
    "\n",
    "\n",
    "#     X_train,X_test, y_train, y_test=train_test_split(X,y,test_size=0.3, random_state=seed) #Seperating into tranin and test\n",
    "\n",
    "\n",
    "\n",
    "#     model=RandomForestClassifier(n_estimators=num_trees, max_features=num_features, random_state=seed) #model\n",
    "    \n",
    "#     results=cross_val_score(model, X, y, cv=kfold) #CV\n",
    "\n",
    "\n",
    "\n",
    "#     # Accuracy Before Pickling the model\n",
    "#     print(f'Random Forest - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "\n",
    "\n",
    "#     model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "#     # Now we save it into a file\n",
    "#     filename=\"PaulaMoya_RFC_model.sav\"\n",
    "#     dump(model, open(filename, \"wb\"))\n",
    "#     # .... some time later .... \n",
    "#     #load the model from disk\n",
    "#     loaded_model=load(open(filename, \"rb\"))\n",
    "#     result=loaded_model.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "#     # Accuracy After Pickling and loading the model\n",
    "#     print(f'Loaded model - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#     from sklearn.linear_model import LinearRegression       # if large--> r square\n",
    "#                                                             # if part of data--> does not work well!! \n",
    "#     kfold=KFold(n_splits=2, random_state=7)                # sklearn better higher w fi chi bel ma2loub!! \n",
    "#                                         #same results BUT DIFFERENT WAY TO USE IT!!\n",
    "#     model=LinearRegression()\n",
    "#     scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "#     results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "#     print(f'Linear Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "#     # res_w1[\"Res\"]=results\n",
    "#     # res_w1[\"Type\"]=\"Lin\"\n",
    "\n",
    "#     # resall=pd.concat([resall,res_w1], ignore_index=True)\n",
    "\n",
    "#     # Now lets use it in the same way than the statsmodel\n",
    "    \n",
    "    \n",
    "    \n",
    "#     len(data[\"host_response_rate\"])\n",
    "\n",
    "#     model_x=LinearRegression()\n",
    "#     model_x.fit(X,y)\n",
    "#     print(f'Intercept {model_x.intercept_:.4f}')\n",
    "#     print(\"Coefficients \",model_x.coef_)\n",
    "\n",
    "#     y_pred_x=model_x.predict(X)\n",
    "\n",
    "#     print(f'MAE - Mean Absolute Error {metrics.mean_absolute_error(y, y_pred_x):.3f}')\n",
    "#     print(f'MSE - Mean Square Error  {metrics.mean_squared_error(y, y_pred_x):.3f}')\n",
    "#     print(f'R2    {metrics.r2_score(y, y_pred_x):.3f}')    \n",
    "    \n",
    "    \n",
    "#     from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "#     clf = LinearRegression()\n",
    "#     y = data['price_per_night']\n",
    "#     clf.fit(data.drop('price_per_night', axis='columns'), y)\n",
    "\n",
    "#     y_pred = clf.predict(data.drop('price_per_night', axis='columns'))\n",
    "    \n",
    "#     import sklearn.metrics\n",
    "#     mse = sklearn.metrics.mean_squared_error(y, y_pred)\n",
    "#     print(\"mse:\")\n",
    "#     mse\n",
    "    \n",
    "    \n",
    "#     root_mse = mse**(1/2)\n",
    "#     print(\"root_mse:\")\n",
    "#     root_mse    #by how much we're missing out\n",
    "    \n",
    "#     print(\"r_squared:\")\n",
    "#     r_squared = sklearn.metrics.r2_score(y, y_pred)\n",
    "#     r_squared          #how much of the variance are we predicting\n",
    "    \n",
    "    # WE STILL HAVE ID TO LINK IT TO THE CALENDAR TABLE!\n",
    "\n",
    "#     y = data[\"price_per_night\"] # Target variable (price_per_night)\n",
    "#     X_wnei = data.drop([\"price_per_night\"],axis=1)\n",
    "    \n",
    "#     # Creating new DF without neighborhood names\n",
    "#     X_wnei.to_csv(\"X_wnei.csv\", index=False)\n",
    "#     data.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host_is_superhost\n",
    "# host_identity_verified \n",
    "# accommodates                        \n",
    "# bathrooms                           \n",
    "# bedrooms                            \n",
    "# beds                                \n",
    "# Wheelchair_bool                     \n",
    "# TV_bool                             \n",
    "# Hair Dryer_bool                     \n",
    "# 24-Hour_Check-in_bool               \n",
    "# Doorman_bool                        \n",
    "# Gym_bool                            \n",
    "# Kitchen_bool                        \n",
    "# Smoke_Detector_bool                 \n",
    "# Clothes_Dryer_bool                  \n",
    "# Kitchen_boolean     \n",
    "# Elevator_in_building_bool \n",
    "# Heating_bool\n",
    "\n",
    "# AC_bool                             \n",
    "# Internet_bool \n",
    "\n",
    "# cleaning_fee                        \n",
    "# guests_included \n",
    "\n",
    "# instant_bookable                    \n",
    "# super_strict_canc\n",
    "\n",
    "# require_guest_profile_picture  \n",
    "# require_guest_phone_verification \n",
    "\n",
    "# Allston                             \n",
    "# Back Bay                            \n",
    "# Bay Village                     \n",
    "# Beacon Hill                         \n",
    "# Brighton                            \n",
    "# Charlestown                         \n",
    "# Chinatown                           \n",
    "# Dorchester                          \n",
    "# Downtown                            \n",
    "# East Boston                         \n",
    "# Fenway                              \n",
    "# Hyde Park                           \n",
    "# Jamaica Plain                       \n",
    "# Leather District                    \n",
    "# Longwood Medical Area               \n",
    "# Mattapan                            \n",
    "# Mission Hill                        \n",
    "# North End                           \n",
    "# Roslindale                          \n",
    "# Roxbury                     \n",
    "# South Boston                        \n",
    "# South Boston Waterfront             \n",
    "# South End                           \n",
    "# West End                            \n",
    "# West Roxbury                       \n",
    "# Entire home/apt                     \n",
    "# Private room                        \n",
    "# Shared room   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
