{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "import matplotlib\n",
    "import sklearn\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.9)\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "# TO WORK WITH\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import set_printoptions\n",
    "\n",
    "# HIDE WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PREPROCESSING & MODEL SELECTION\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, RidgeCV, LassoCV, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import SCORERS\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# print(SCORERS.keys())\n",
    "\n",
    "# PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.lines as mlines\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "import plotly.express as px\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# STANDARD MODELS\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# ENSEMBLE\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# CLUSTERING\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# PICKLE\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split(data):  \n",
    "    '''\n",
    "    Clean the data and return an array for the target variable and all the input variables\n",
    "\n",
    "    '''    \n",
    "    data=data.dropna()\n",
    "    \n",
    "    data=data[data[\"price_per_night\"]>=12]\n",
    "    data=data[data[\"number_of_reviews\"]>=1]\n",
    "    data=data[data[\"guests_included\"]>=1]\n",
    "    \n",
    "    \n",
    "\n",
    "    data['extra_price']=data['security_deposit']+data['cleaning_fee']+data['extra_people']\n",
    "    data['extra_price'].describe()\n",
    "    \n",
    "    \n",
    "    for test in data['extra_price']:\n",
    "       \n",
    "        if test<25:\n",
    "            data['extra_price']=25\n",
    "    \n",
    "    \n",
    "        if 25<test and test<100:\n",
    "            data['extra_price']=75\n",
    "    \n",
    "    \n",
    "        if 100<test and test<235:\n",
    "            data['extra_price']=125\n",
    "    \n",
    "    \n",
    "        if 235<test:\n",
    "            data['extra_price']=235\n",
    "            \n",
    "    \n",
    "    for categorical_feature in ['neighbourhood_cleansed',\"property_type\",\"room_type\"]:\n",
    "        data = pd.concat([data,pd.get_dummies(data[categorical_feature], prefix=categorical_feature, prefix_sep='_',)], axis=1)\n",
    "        \n",
    "    \n",
    "    data= data.drop(['neighbourhood_cleansed', 'property_type', 'room_type','description','host_about_bool',\n",
    "                    'amenities',\"house_rules\",\"review_scores_cleanliness\",\"review_scores_rating\",'review_scores_accuracy',              \n",
    "                    'review_scores_cleanliness','review_scores_checkin','review_scores_communication','review_scores_value',\n",
    "                     'id',\"property_type\", \"host_response_rate\", 'reviews_per_month','number_of_reviews'\n",
    "                     ,'security_deposit','cleaning_fee','extra_people','extra_price','availability_365'],axis=1)\n",
    "    \n",
    "    \n",
    "    y = data[\"price_per_night\"] # Target variable (price_per_night)\n",
    "    \n",
    "    X = data.drop([\"price_per_night\"],axis=1) \n",
    "\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB(X,y):\n",
    "    '''\n",
    "    Calculating RMSE with XGBoost Hyperparameters\n",
    "\n",
    "    '''\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "    xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                max_depth = 7, alpha = 20, n_estimators = 70)\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "\n",
    "    preds = xg_reg.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinReg(X,y):\n",
    "    '''\n",
    "    Performing Linear Regression with scikit-learn\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression       \n",
    "                                                         \n",
    "    kfold=KFold(n_splits=10, random_state=7)                \n",
    "                                   \n",
    "    model=LinearRegression()\n",
    "    scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "    results=cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "    print(f'Linear Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "\n",
    "    # Now lets use it in the same way than the statsmodel\n",
    "\n",
    "    model_x=LinearRegression()\n",
    "    model_x.fit(X,y)\n",
    "    print(f'Intercept {model_x.intercept_:.4f}')\n",
    "    print(\"Coefficients \",model_x.coef_)\n",
    "\n",
    "    y_pred_x=model_x.predict(X)\n",
    "    \n",
    "    regressor = LinearRegression()  \n",
    "    regressor.fit(X, y)\n",
    "    print(\"predict\")\n",
    "    y_pred = regressor.predict(X)\n",
    "    df = pd.DataFrame({'Actual': y, 'Predicted': y_pred})\n",
    "    df.head(25)\n",
    "    print(df)\n",
    "\n",
    "\n",
    "    print(f'MAE - Mean Absolute Error {metrics.mean_absolute_error(y, y_pred_x):.3f}')\n",
    "    print(f'MSE - Mean Square Error  {metrics.mean_squared_error(y, y_pred_x):.3f}')\n",
    "    print(f'R2    {metrics.r2_score(y, y_pred_x):.3f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"listings_8.csv\")\n",
    "\n",
    "X,y= split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:50:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.0.0/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE: 62.013981\n"
     ]
    }
   ],
   "source": [
    "XGB(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE -247339948278107662786047770624.000 std 742017984384899230796190056448.000\n",
      "Intercept -42167051653739.7734\n",
      "Coefficients  [-3.30923961e+00 -2.94685902e+00  7.83000964e+00 -3.95446917e+01\n",
      " -4.54969204e+01 -3.40970068e+01 -2.39027639e+01  1.18635114e+01\n",
      "  7.36786495e-01 -4.11650556e-01  4.64321848e+00  2.39303359e+01\n",
      "  4.93787630e+01  4.74837320e+00  6.69160690e+00  1.70138058e+01\n",
      "  2.84804693e+00 -1.40903687e+01  1.34778252e+01 -1.41159208e+01\n",
      " -2.17052243e+12  9.39628472e+00 -1.19046522e+00  2.17052243e+12\n",
      "  9.68525614e+00  5.77941984e+00 -5.84684273e+00  7.46324016e-01\n",
      "  1.26432205e+01  1.64175684e+00  6.28915287e+00 -2.22660678e+01\n",
      "  4.09343750e+00 -1.06646347e+01  2.77432861e+01 -6.06530376e+12\n",
      " -6.06530376e+12 -6.06530376e+12 -1.67700195e+01  2.32590332e+01\n",
      "  1.27366058e+13  1.27366058e+13  1.27366058e+13  1.27366058e+13\n",
      "  1.27366058e+13  1.27366058e+13  1.27366058e+13  1.27366058e+13\n",
      "  1.27366058e+13  1.27366058e+13  1.27366058e+13  1.27366058e+13\n",
      "  1.27366058e+13  1.27366058e+13  1.27366058e+13  1.27366058e+13\n",
      "  1.27366058e+13  1.27366058e+13  1.27366058e+13  1.27366058e+13\n",
      "  1.27366058e+13  1.27366058e+13  1.27366058e+13  1.27366058e+13\n",
      "  1.27366058e+13 -1.94759864e+11 -1.94759864e+11 -1.94759864e+11\n",
      " -1.94759864e+11 -1.94759864e+11 -1.94759864e+11 -1.94759864e+11\n",
      " -1.94759864e+11 -1.94759864e+11 -1.94759864e+11 -1.94759864e+11\n",
      " -1.94759864e+11  3.56905095e+13  3.56905095e+13  3.56905095e+13]\n",
      "predict\n",
      "      Actual   Predicted\n",
      "0        160  229.070312\n",
      "1        250  224.421875\n",
      "2        210  223.789062\n",
      "4        185  218.281250\n",
      "5         50  126.171875\n",
      "...      ...         ...\n",
      "2759     200   73.070312\n",
      "2760     450  328.859375\n",
      "2762      45   99.328125\n",
      "2765     155  160.960938\n",
      "2767      65    5.632812\n",
      "\n",
      "[2181 rows x 2 columns]\n",
      "MAE - Mean Absolute Error 41.161\n",
      "MSE - Mean Square Error  3821.006\n",
      "R2    0.692\n"
     ]
    }
   ],
   "source": [
    "LinReg(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data.info()\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "# df1 = df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
